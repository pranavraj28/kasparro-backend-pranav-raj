Kasparro Backend & ETL Assignment
This repository contains my submission for the Kasparro Backend Engineer Internship Assignment.
It implements a production-ready ETL pipeline with canonical asset normalization, persistent storage, and a public API.

ğŸš€ Live Public Cloud Deployment (Verified)
The system is live, publicly deployed, and verifiable.

ğŸ”— Deployed Backend URL (Render)
ğŸ‘‰ https://kasparro-backend-agwk.onrender.com

âœ… Verification Endpoints
Health / Root
https://kasparro-backend-agwk.onrender.com/

Unified Canonical Data API
https://kasparro-backend-agwk.onrender.com/data

Swagger API Documentation
https://kasparro-backend-agwk.onrender.com/docs

This deployment satisfies the public cloud deployment requirement of the assignment and can be verified without any local setup.

ğŸ“Œ Assignment Scope Covered
âœ” Public cloud deployment (Render)
âœ” Dockerized backend
âœ” Executable ETL system
âœ” Canonical asset normalization across multiple sources
âœ” Checkpoint-based ingestion
âœ” Verifiable API output
âœ” No hardcoded secrets
âœ” Real data sources (CoinPaprika, CoinGecko)

ğŸ§  System Overview
The system ingests cryptocurrency market data from multiple sources, normalizes assets into canonical coins, and exposes unified results through a REST API.

Data Sources
CoinPaprika API

CoinGecko API

Key Features
Canonical coin unification (e.g., BTC across sources)

Source-to-canonical mapping

Latest price selection per asset

Idempotent ETL runs

Docker-based execution

Public API for consumption

ğŸ—‚ Project Structure
kasparro-etl/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app entrypoint
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â””â”€â”€ data.py           # /data endpoint
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ database/             # DB session & initialization
â”‚   â”‚   â”œâ”€â”€ logging/              # Centralized logging
â”‚   â”‚   â””â”€â”€ models.py             # SQLAlchemy models
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ base.py               # Ingestion base class
â”‚   â”‚   â”œâ”€â”€ coinpaprika.py
â”‚   â”‚   â”œâ”€â”€ coingecko.py
â”‚   â”‚   â””â”€â”€ normalize.py          # Canonical normalization logic
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_etl.py                    # ETL execution entrypoint
â””â”€â”€ README.md
ğŸ” ETL & Normalization Logic
Canonical Coin Model
Each coin exists once in the system

Multiple sources map to a single canonical coin

Prices are always stored against the canonical entity

Normalization Flow
Fetch raw data from source

Normalize symbol (e.g., aliases â†’ canonical symbol)

Create or reuse canonical coin

Store source mapping

Insert latest price snapshot

This prevents duplication and ensures clean downstream consumption.

ğŸŒ API Details
GET /data
Returns unified canonical coins with all available sources and latest price.

Example Response

[
  {
    "symbol": "BTC",
    "name": "Bitcoin",
    "sources": ["coingecko", "coinpaprika"],
    "latest_price_usd": 87593.11
  }
]
ğŸ³ Docker & Execution
Run Locally (Optional)
docker compose up --build
Run ETL Manually
docker compose exec api python run_etl.py
ğŸ” Secrets & Configuration
No secrets are hardcoded

API keys are optional

System works without paid API access

Production deployment uses environment-based configuration
